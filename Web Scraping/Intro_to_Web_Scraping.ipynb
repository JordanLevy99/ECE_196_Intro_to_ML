{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo... 3 exercises on webscraping at http://example.webscraping.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction to Web Scraping**\n",
    "\n",
    "In this notebook we will be doing some introductory exercises at http://example.webscraping.com/  to get familiar to webscraping with BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get HTML text of a webpage using requests.get(url).text, then create a BeautifulSoup object using BeautifulSoup(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('http://example.webscraping.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_text = requests.get('http://example.webscraping.com/').text\n",
    "soup = BeautifulSoup(url_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup is an HTML parser that will allow us to traverse the 'HTML tree' each website has."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0)** Check the robots.txt at example.webscraping.com: this will tell us how often we can send requests to their website.\n",
    "\n",
    "They recommend a crawl-delay of 5 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Extract the title of example.webscraping.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>\n",
       "                    Example web scraping website\n",
       "                    <small></small>\n",
       "</h1>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.find('h1').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n                    Example web scraping website\\n                    \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title.strip('\\n').strip(' ').strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Example web scraping website'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Get the name of the first country to appear on http://example.webscraping.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find structure in the webpage such that we could find the name of this country without knowing it's name beforehand.  This will come in handy when scraping many webpages at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"dropdown-toggle\" data-toggle=\"dropdown\" href=\"#\" rel=\"nofollow\">Log In</a>,\n",
       " <a href=\"/places/default/user/register?_next=/places/default/index\" rel=\"nofollow\"><i class=\"icon icon-user glyphicon glyphicon-user\"></i> Sign Up</a>,\n",
       " <a href=\"/places/default/user/login?_next=/places/default/index\" rel=\"nofollow\"><i class=\"icon icon-off glyphicon glyphicon-off\"></i> Log In</a>,\n",
       " <a href=\"/places/default/index\">Home</a>,\n",
       " <a href=\"/places/default/search\">Search</a>,\n",
       " <a href=\"/places/default/view/Afghanistan-1\"><img src=\"/places/static/images/flags/af.png\"/> Afghanistan</a>,\n",
       " <a href=\"/places/default/view/Aland-Islands-2\"><img src=\"/places/static/images/flags/ax.png\"/> Aland Islands</a>,\n",
       " <a href=\"/places/default/view/Albania-3\"><img src=\"/places/static/images/flags/al.png\"/> Albania</a>,\n",
       " <a href=\"/places/default/view/Algeria-4\"><img src=\"/places/static/images/flags/dz.png\"/> Algeria</a>,\n",
       " <a href=\"/places/default/view/American-Samoa-5\"><img src=\"/places/static/images/flags/as.png\"/> American Samoa</a>,\n",
       " <a href=\"/places/default/view/Andorra-6\"><img src=\"/places/static/images/flags/ad.png\"/> Andorra</a>,\n",
       " <a href=\"/places/default/view/Angola-7\"><img src=\"/places/static/images/flags/ao.png\"/> Angola</a>,\n",
       " <a href=\"/places/default/view/Anguilla-8\"><img src=\"/places/static/images/flags/ai.png\"/> Anguilla</a>,\n",
       " <a href=\"/places/default/view/Antarctica-9\"><img src=\"/places/static/images/flags/aq.png\"/> Antarctica</a>,\n",
       " <a href=\"/places/default/view/Antigua-and-Barbuda-10\"><img src=\"/places/static/images/flags/ag.png\"/> Antigua and Barbuda</a>,\n",
       " <a href=\"/places/default/index/1\">Next &gt;</a>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td><div><a href=\"/places/default/view/Afghanistan-1\"><img src=\"/places/static/images/flags/af.png\"/> Afghanistan</a></div></td>,\n",
       " <td><div><a href=\"/places/default/view/Aland-Islands-2\"><img src=\"/places/static/images/flags/ax.png\"/> Aland Islands</a></div></td>,\n",
       " <td><div><a href=\"/places/default/view/Albania-3\"><img src=\"/places/static/images/flags/al.png\"/> Albania</a></div></td>,\n",
       " <td><div><a href=\"/places/default/view/Algeria-4\"><img src=\"/places/static/images/flags/dz.png\"/> Algeria</a></div></td>,\n",
       " <td><div><a href=\"/places/default/view/American-Samoa-5\"><img src=\"/places/static/images/flags/as.png\"/> American Samoa</a></div></td>,\n",
       " <td><div><a href=\"/places/default/view/Andorra-6\"><img src=\"/places/static/images/flags/ad.png\"/> Andorra</a></div></td>,\n",
       " <td><div><a href=\"/places/default/view/Angola-7\"><img src=\"/places/static/images/flags/ao.png\"/> Angola</a></div></td>,\n",
       " <td><div><a href=\"/places/default/view/Anguilla-8\"><img src=\"/places/static/images/flags/ai.png\"/> Anguilla</a></div></td>,\n",
       " <td><div><a href=\"/places/default/view/Antarctica-9\"><img src=\"/places/static/images/flags/aq.png\"/> Antarctica</a></div></td>,\n",
       " <td><div><a href=\"/places/default/view/Antigua-and-Barbuda-10\"><img src=\"/places/static/images/flags/ag.png\"/> Antigua and Barbuda</a></div></td>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td><div><a href=\"/places/default/view/Afghanistan-1\"><img src=\"/places/static/images/flags/af.png\"/> Afghanistan</a></div></td>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('td')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Afghanistan'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country = soup.find_all('td')[0].text\n",
    "country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Afghanistan'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country = country.strip()\n",
    "country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Get the name of the third country to appear on the second page of countries at http://example.webscraping.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete this task, we will have to traverse away from http://example.webscraping.com/ to the second page of countries.  We could do this manually, but we will be implementing a programmatic way to do so, so we can traverse multiple pages at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_number = 2\n",
    "url = f'http://example.webscraping.com/places/default/index/{page_number-1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_text = requests.get(url).text\n",
    "soup2 = BeautifulSoup(url_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Aruba'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country = soup2.find_all('td')[2].text  # Gets the third 'td' element on the page\n",
    "country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aruba'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country = country.strip()\n",
    "country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** Get the names of all the country at http://example.webscraping.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a basic understanding of how different pages of country names are accessed and how the country names are structured within each page, we can write a script to get the names of all countries and append them to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.codes.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 0 Done\n",
      "Page 1 Done\n",
      "Page 2 Done\n",
      "Page 3 Done\n",
      "Page 4 Done\n",
      "Page 5 Done\n",
      "Page 6 Done\n",
      "Page 7 Done\n",
      "Page 8 Done\n",
      "Page 9 Done\n",
      "Page 10 Done\n",
      "Bad Request\n"
     ]
    }
   ],
   "source": [
    "total_countries = []\n",
    "for page in range(200):\n",
    "    url = f'http://example.webscraping.com/places/default/index/{page}'\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        url_text = r.text\n",
    "    else:\n",
    "        print('Bad Request')\n",
    "        break\n",
    "    soup = BeautifulSoup(url_text)\n",
    "    country_list_page = soup.find_all('td')  # gets a list of all elements that contain country names\n",
    "    if len(country_list_page) == 0:\n",
    "        print('All Countries extracted')\n",
    "        break\n",
    "    for elem in country_list_page:\n",
    "        country = elem.text\n",
    "        total_countries.append(country)\n",
    "    print(f'Page {page} Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_countries = []\n",
    "# for page in range(200):\n",
    "#     url = f'http://example.webscraping.com/places/default/index/{page}'\n",
    "#     r = requests.get(url)\n",
    "#     if r.status_code == requests.codes.ok:\n",
    "#         url_text = r.text\n",
    "#     else:\n",
    "#         print('Bad Request')\n",
    "#         print('Trying again in 5 seconds...')\n",
    "#         page -= 1\n",
    "#         time.sleep(5)\n",
    "#         continue\n",
    "#     soup = BeautifulSoup(url_text)\n",
    "#     country_list_page = soup.find_all('td')  # gets a list of all elements that contain country names\n",
    "#     if len(country_list_page) == 0:\n",
    "#         print('All Countries Extracted')\n",
    "#         break\n",
    "#     for elem in country_list_page:\n",
    "#         country = elem.text\n",
    "#         total_countries.append(country)\n",
    "#     print(f'Page {page} Done')\n",
    "# #     time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_countries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
