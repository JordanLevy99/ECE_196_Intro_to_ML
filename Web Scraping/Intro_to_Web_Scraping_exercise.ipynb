{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECE 196 Introduction to Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Whenever you see '...', replace with a line of code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'c'\n",
    "content = requests.get(base_url).content\n",
    "soup = BeautifulSoup(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0) Check the robots.txt of example.webscraping.com**\n",
    "\n",
    "Add robots.txt to the end of the base_url and read what is there.\n",
    "\n",
    "Note the 'Crawl-delay' on the robots.txt.  'Craw-delay' is the amount of seconds the user is expected to wait before sending another request, if scraping multiple webpages from the website at once.  We can implement this with the time.sleep(seconds) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Get the names of all the countries on the first page**\n",
    "\n",
    "Hint: A tag starts with &lt;tag> and ends with &lt;/tag>.\n",
    "\n",
    "Hint: Use inspect element to find the html of a page.\n",
    "\n",
    "Hint: Use soup.find() and .find_all()\n",
    "\n",
    "Hint: Find the tag &lt;div id=\"results\"> under the &lt;section id=\"main\" class=\"main row\"> tag in BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: Return a list of names (all strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Note: The skeleton code is just a suggestion, feel free to write the code however you wish\n",
    "country_links = ...  # find a list of <a> tags for each of the countries on the page\n",
    "country_lst = ...  # Get the .text attribute of <a> tags for each <a> tag in country_links\n",
    "country_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Get the size of Albania in square kilometers**\n",
    "\n",
    "Hint: use soup.find_all(tag, {attr_name:value}) to isolate lines of HTML with that tag and attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: Return a string, example: 'X square kilometers' where X is the number of square kilometers of Albania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://example.webscraping.com/places/default/view/Albania-3'\n",
    "content = requests.get(url).content\n",
    "soup = BeautifulSoup(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = ... # Find the tag that has the size, get the .text attribute of this tag\n",
    "size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Find the population per square kilometers of China**\n",
    "\n",
    "Given the url listing all countries in Asia, find the population per square kilometer of China. \n",
    "\n",
    "Hint: You will need to find the url for China in the webpage, then use the requests module to get the content of that page.\n",
    "\n",
    "Hint: String methods like .split(str), .strip(str), and .replace(str) may be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: Return a float of population / square kilometer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://example.webscraping.com/places/default/view/China-47'\n",
    "# Based on the last two problems, fill in the code for 'content', 'soup', and 'country_links'\n",
    "content = ...  # Using the requests module, get the content of the webpage at the url listed above\n",
    "soup = ... # Initialize a BeautifulSoup object accordingly\n",
    "\n",
    "size =   # Get the size of China in square kilometers\n",
    "population = ... # Get the population of China in square kilometers\n",
    "\n",
    "size = int(...)  # Extract the number itself, with no commas or extraneous characters\n",
    "population = int(...)  # Extract the number itself, with no commas or extraneous characters\n",
    "\n",
    "...  # Output the float of population per square kilometer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
